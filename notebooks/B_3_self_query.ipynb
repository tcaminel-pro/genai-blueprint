{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Self Query Retriever\n",
                "\n",
                "This notebook demonstrates **self-query retrieval** - where an LLM helps translate natural language queries into structured database queries.\n",
                "\n",
                "Key benefits:\n",
                "- Lets users ask questions in natural language\n",
                "- Automatically converts to optimized database queries\n",
                "- Supports filtering by multiple metadata fields\n",
                "\n",
                "Implementation adapted from:\n",
                "- [LangChain Self-Query Retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/)\n",
                "- [Query Construction Blog Post](https://blog.langchain.dev/query-construction/)\n",
                "\n",
                "The core implementation is in [ai_chains/B_2_self_query.py](../python/ai_chains/B_2_self_query.py)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup Environment\n",
                "\n",
                "First we configure the environment:\n",
                "- Load environment variables (API keys, etc)\n",
                "- Enable automatic reloading for development\n",
                "- Import required libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from dotenv import load_dotenv\n",
                "from rich import print as rprint\n",
                "\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "load_dotenv(verbose=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Import Self-Query Components\n",
                "\n",
                "We'll use two main functions from our implementation:\n",
                "\n",
                "1. `get_query_constructor()` - Creates the LLM-powered query translator\n",
                "2. `get_retriever()` - Configures the full retrieval pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from genai_tk.chains.B_2_self_query import get_query_constructor, get_retriever"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test Query Construction\n",
                "\n",
                "Let's see how the query constructor translates natural language into a structured query:\n",
                "\n",
                "- Input: Natural language question about movies\n",
                "- Output: Structured query with filters for:\n",
                "  - Genre (sci-fi)\n",
                "  - Decade (1990s)\n",
                "  - Director (Luc Besson)\n",
                "  - Theme (taxi drivers)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from genai_blueprint.utils.config_mngr import global_config\n",
                "\n",
                "global_config().set(\"embeddings.default\", \"ada_002_azure\")\n",
                "\n",
                "\n",
                "query_constructor = get_query_constructor({})\n",
                "query = query_constructor.invoke(\n",
                "    {\"query\": \"What are some sci-fi movies from the 90's directed by Luc Besson about taxi drivers\"}\n",
                ")\n",
                "print(query)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from rich import print\n",
                "\n",
                "print(query)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Full Retrieval Pipeline\n",
                "\n",
                "Now let's test the complete self-query retriever:\n",
                "\n",
                "1. Configured with GPT-4 for query understanding\n",
                "2. Takes natural language input\n",
                "3. Returns matching documents filtered by rating (>8.5)\n",
                "\n",
                "Try modifying the query to test different filters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# retriever = get_retriever(config={\"llm\": None})\n",
                "\n",
                "\n",
                "from devtools import debug\n",
                "\n",
                "retriever = get_retriever(config={\"llm\": \"gpt_4omini_openai\"})\n",
                "debug(retriever)\n",
                "result = retriever.invoke(\"I want to watch a movie rated higher than 8.5\")\n",
                "rprint(result)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "genai-blueprint (3.12.3)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}