{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image to Text with LCEL\n",
    "\n",
    "Note : API evolves.  See also : \n",
    "- https://python.langchain.com/docs/how_to/multimodal_inputs/\n",
    "- https://python.langchain.com/docs/how_to/multimodal_prompts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from genai_blueprint.utils.config_mngr import global_config\n",
    "from genai_tk.core.llm_factory import get_llm\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from upath import UPath\n",
    "\n",
    "load_dotenv(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Modal Chain Construction\n",
    "\n",
    "This chain combines three components:\n",
    "1. **Prompt Generation**: Creates structured messages with system instructions and user content\n",
    "2. **LLM Selection**: Configures GPT-4o for image understanding capabilities\n",
    "3. **Output Parsing**: Converts LLM response to clean text output\n",
    "\n",
    "The chain handles both text prompts and image inputs in a single query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prompt(param_dict: dict) -> list[BaseMessage]:\n",
    "    # Function to generate a prompt based on given parameters\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant that kindly explains images and answers questions provided by the user.\"\n",
    "    )\n",
    "    human_messages = [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"{param_dict['question']}\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"{param_dict['image_url']}\",\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "    return [SystemMessage(content=system_message), HumanMessage(content=human_messages)]\n",
    "\n",
    "\n",
    "llm = get_llm(llm_tag=\"for_vision\")\n",
    "\n",
    "chain = gen_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genai_blueprint.utils.config_mngr import global_config\n",
    "\n",
    "global_config().get_str(\"default_config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Handling & Base64 Encoding\n",
    "\n",
    "Key technical details:\n",
    "- Images are converted to base64 strings for API compatibility\n",
    "- Path resolution uses centralized configuration\n",
    "- Supports both local files and external URLs\n",
    "- Automatic encoding/decoding preserves image fidelity\n",
    "\n",
    "The `encode_image` function handles binary-to-text conversion required for JSON payloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = global_config().get_dir_path(\"paths.project\")\n",
    "IMAGE_PATH = BASE / \"use_case_data/other/reference-architecture-magento.png\"\n",
    "QUESTION = \"List the AWS services used in that architecture.  To What Amazon CloudFront is connected ?\"\n",
    "\n",
    "\n",
    "def encode_image(image_path: UPath) -> str:\n",
    "    # Open the image file and encode it as a base64 string\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "base64_image = encode_image(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"question\": QUESTION,\n",
    "        \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  With EdenAI API (can be skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import requests\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {os.environ['EDENAI_API_KEY']}\"}\n",
    "url = \"https://api.edenai.run/v2/multimodal/chat\"\n",
    "\n",
    "\n",
    "# Function to read the image file and convert it to base64\n",
    "with open(IMAGE_PATH, \"rb\") as image_file:\n",
    "    base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "payload = {\n",
    "    \"providers\": \"openai, google\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"content\": {\"text\": QUESTION},\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"media_base64\",\n",
    "                    \"content\": {\n",
    "                        \"media_base64\": base64_image,\n",
    "                        \"media_type\": \"image/png\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"chatbot_global_action\": \"\",\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "result = response.json()\n",
    "print(result[\"openai\"][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"google\"][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-blueprint (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}