{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "This notebook demonstrates how to work with text embeddings using various models. \n",
    "\n",
    "Embeddings are numerical representations of text that capture semantic meaning, allowing us to perform operations like similarity comparison and clustering.\n",
    "\n",
    "We'll explore:\n",
    "- Loading different embedding models\n",
    "- Generating embeddings for text\n",
    "- Calculating similarity between embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'genai_tk.core.embeddings_factory'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m sys.modules[\u001b[33m\"\u001b[39m\u001b[33mgenai_tk\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m sys.modules[\u001b[33m\"\u001b[39m\u001b[33mgenai_tk.core\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgenai_tk.core.embeddings_factory\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mKeyError\u001b[39m: 'genai_tk.core.embeddings_factory'"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "assert find_dotenv(), \"no .env file found\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "!export PYTHONPATH=$PYTHONPATH:$(pwd)\n",
    "\n",
    "# Force reload modules (add this cell and run it first)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Clear any cached imports\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "if \"genai_tk\" in sys.modules:\n",
    "    del sys.modules[\"genai_tk\"]\n",
    "    del sys.modules[\"genai_tk.core\"]\n",
    "    del sys.modules[\"genai_tk.core.embeddings_factory\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_1 = \"Tokenization is the process of breaking down a text into individual units.\"\n",
    "SENTENCE_2 = \"Tokens can be words, phrases, or even individual characters.\"\n",
    "SENTENCE_3 = \"LangChain Provide a standardized way to load and process various types of documents\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available Embedding Models\n",
    "\n",
    "Our system provides a factory pattern for creating different embedding models. \n",
    "\n",
    "The available models are defined in [embeddings.py](../python/ai_core/embeddings.py).\n",
    "\n",
    "Let's list all available models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "cannot find config file: '/home/tcl/prj/genai-blueprint/notebooks/config/app_conf.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgenai_tk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings_factory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EmbeddingsFactory, get_embeddings\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#from src.ai_core.embeddings_factory import EmbeddingsFactory, get_embeddings\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(EmbeddingsFactory.known_items())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prj/genai-blueprint/.venv/lib/python3.12/site-packages/genai_tk/core/embeddings_factory.py:42\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mloguru\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logger\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field, computed_field\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgenai_tk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextra\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkv_store_factory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KvStoreFactory\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgenai_tk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_mngr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m global_config\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgenai_tk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproviders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_provider_api_env_var, get_provider_api_key\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prj/genai-blueprint/.venv/lib/python3.12/site-packages/genai_tk/extra/kv_store_factory.py:15\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgenai_tk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_mngr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m global_config\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m kvstore_config = \u001b[43mglobal_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.get_dict(\u001b[33m\"\u001b[39m\u001b[33mkv_store\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mKvStoreFactory\u001b[39;00m(BaseModel):\n\u001b[32m     19\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Factory for creating key-value stores with configurable backends.\u001b[39;00m\n\u001b[32m     20\u001b[39m \n\u001b[32m     21\u001b[39m \u001b[33;03m    Attributes:\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m        id: Identifier for the storage backend type\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m        root: Root namespace or directory for the storage\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prj/genai-blueprint/.venv/lib/python3.12/site-packages/genai_tk/utils/config_mngr.py:286\u001b[39m, in \u001b[36mglobal_config\u001b[39m\u001b[34m(reload)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reload:\n\u001b[32m    285\u001b[39m     global_config_reload()\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOmegaConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43msingleton\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prj/genai-blueprint/.venv/lib/python3.12/site-packages/genai_tk/utils/singleton.py:124\u001b[39m, in \u001b[36monce_fn.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m decorator._lock:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m decorator._cached_results:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m             decorator._cached_results[cache_key] = result  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m decorator._cached_results[cache_key]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prj/genai-blueprint/.venv/lib/python3.12/site-packages/genai_tk/utils/config_mngr.py:59\u001b[39m, in \u001b[36mOmegaConfig.singleton\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m app_conf_path.exists():\n\u001b[32m     58\u001b[39m     app_conf_path = Path(\u001b[33m\"\u001b[39m\u001b[33mconfig/app_conf.yaml\u001b[39m\u001b[33m\"\u001b[39m).absolute()\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m app_conf_path.exists(), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcannot find config file: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapp_conf_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m OmegaConfig.create(app_conf_path)\n",
      "\u001b[31mAssertionError\u001b[39m: cannot find config file: '/home/tcl/prj/genai-blueprint/notebooks/config/app_conf.yaml'"
     ]
    }
   ],
   "source": [
    "from genai_tk.core.embeddings_factory import EmbeddingsFactory, get_embeddings\n",
    "\n",
    "# from src.ai_core.embeddings_factory import EmbeddingsFactory, get_embeddings\n",
    "\n",
    "print(EmbeddingsFactory.known_items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create embeddings for our first sentence using different models.\n",
    "\n",
    "We'll use cosine similarity to compare how similar the embeddings are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Embeddings\n",
    "\n",
    "\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "\n",
    "# Try different models by uncommenting one:\n",
    "MODEL_ID = \"ada_002_azure\"\n",
    "MODEL_ID = None  # Default\n",
    "embedder = get_embeddings(embeddings_id=MODEL_ID)\n",
    "\n",
    "# or select by tag from a configuration YAML file:\n",
    "# azure_embedder = get_embeddings(embeddings_tag=\"azure\")\n",
    "\n",
    "# Generate embedding for first sentence\n",
    "vector_1 = embedder.embed_documents([SENTENCE_1])\n",
    "print(f\"{vector_1[0][:20]}...\")\n",
    "print(f\"length: {len(vector_1[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare how similar our first sentence is to the other sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Embeddings\n",
    "\n",
    "other_vectors = embedder.embed_documents([SENTENCE_2, SENTENCE_3])\n",
    "\n",
    "result = cosine_similarity(vector_1, other_vectors)\n",
    "print(result)\n",
    "\n",
    "\n",
    "# The output shows the cosine similarity scores between the first sentence and the other two sentences. Scores closer to 1 indicate higher similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vector_1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment\n",
    "\n",
    "1. Try different sentences and observe how the similarity scores change\n",
    "2. Experiment with different embedding models by changing MODEL_ID\n",
    "3. Explore the [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) to compare embedding model performance\n",
    "\n",
    "Some things to try:\n",
    "- How do different models handle synonyms?\n",
    "- What happens with very short vs very long sentences?\n",
    "- How do the embedding dimensions differ between models?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-blueprint (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
