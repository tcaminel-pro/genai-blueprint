{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools Calling with LangGraph React Agent\n",
    "\n",
    "This notebook demonstrates how to use LangGraph's React Agent to:\n",
    "\n",
    "1. Manage complex tool calling workflows\n",
    "2. Handle multiple tools in sequence\n",
    "3. Process and combine tool outputs\n",
    "\n",
    "We'll use EdenAI's suite of tools for:\n",
    "- Text moderation\n",
    "- Object detection\n",
    "- Text-to-speech\n",
    "- And more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment\n",
    "\n",
    "First we configure the environment:\n",
    "- Load environment variables (API keys, etc)\n",
    "- Enable automatic reloading for development\n",
    "- Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "load_dotenv(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Tools and LLM\n",
    "\n",
    "We'll use:\n",
    "- GPT-4 as our primary LLM\n",
    "- EdenAI's suite of tools for various AI tasks\n",
    "\n",
    "The tools include:\n",
    "- Text moderation\n",
    "- Object detection\n",
    "- Text-to-speech\n",
    "- Speech-to-text\n",
    "- Document parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genai_tk.core.llm_factory import get_llm\n",
    "from langchain_community.tools.edenai import (\n",
    "    EdenAiExplicitImageTool,\n",
    "    EdenAiObjectDetectionTool,\n",
    "    EdenAiParsingIDTool,\n",
    "    EdenAiParsingInvoiceTool,\n",
    "    EdenAiSpeechToTextTool,\n",
    "    EdenAiTextModerationTool,\n",
    "    EdenAiTextToSpeechTool,\n",
    ")\n",
    "\n",
    "llm = get_llm()\n",
    "\n",
    "# Define lit of tools\n",
    "\n",
    "tools = [\n",
    "    EdenAiTextModerationTool(providers=[\"openai\"], language=\"en\"),\n",
    "    EdenAiObjectDetectionTool(providers=[\"google\", \"api4ai\"]),\n",
    "    EdenAiTextToSpeechTool(providers=[\"amazon\"], language=\"en\", voice=\"MALE\"),\n",
    "    EdenAiExplicitImageTool(providers=[\"amazon\", \"google\"]),\n",
    "    EdenAiSpeechToTextTool(providers=[\"amazon\"], custom_vocabulary=None, speakers=None),\n",
    "    EdenAiParsingIDTool(providers=[\"amazon\", \"klippa\"], language=\"en\"),\n",
    "    EdenAiParsingInvoiceTool(providers=[\"amazon\", \"google\"], language=\"en\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## React Agent Workflow\n",
    "\n",
    "The React Agent will:\n",
    "1. Analyze the input text\n",
    "2. Determine which tools to use\n",
    "3. Execute tools in sequence\n",
    "4. Combine results into a final response\n",
    "\n",
    "This example checks for explicit content and converts text to speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph Implementation\n",
    "\n",
    "We use LangGraph to:\n",
    "- Create a stateful agent\n",
    "- Manage tool execution flow\n",
    "- Handle intermediate results\n",
    "\n",
    "Note: Current implementation has issues with EdenAI tools - work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "query = \"\"\"i have this text : 'i want to slap you'\n",
    "first : i want to know if this text contains explicit content or not .\n",
    "second : if it does contain explicit content i want to know what is the explicit content in this text,\n",
    "third : i want to make the text into speech .\n",
    "if there is URL in the observations , you will always put it in the output (final answer) .\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "llm = get_llm(llm_tag=\"openrouter\")\n",
    "\n",
    "\n",
    "def is_obscene(input: str) -> bool:\n",
    "    \"\"\"Check if the input string is obscene or not.\"\"\"\n",
    "    return False\n",
    "\n",
    "\n",
    "# DOES NOT WORK with Edenai tools...\n",
    "\n",
    "# tools = [is_obscene]  # This work !\n",
    "\n",
    "agent = create_react_agent(llm, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream) -> None:\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", query)]}\n",
    "print_stream(agent.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "system = \"\"\"You are an agent designed to write and execute python code to answer questions.\n",
    "You have access to a python REPL, which you can use to execute python code.\n",
    "If you get an error, debug your code and try again.\n",
    "Only use the output of your code to answer the question.\n",
    "You might know the answer without running any code, but you should still run the code to get the answer.\n",
    "If it does not seem like you can write code to answer the question, just return \"I don't know\" as the answer.\n",
    "\"\"\"\n",
    "\n",
    "query = \"Using the tools you have, calculate the 10th fibonacci number\"\n",
    "\n",
    "coder_agent = create_react_agent(llm, tools=[PythonREPLTool()])\n",
    "\n",
    "inputs = {\"messages\": [(\"system\", system), (\"user\", query)]}\n",
    "print_stream(coder_agent.stream(inputs, stream_mode=\"values\"))\n",
    "\n",
    "# agent.invoke(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-blueprint (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}